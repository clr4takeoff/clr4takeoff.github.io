---
title: "Daily Podcast #15"
categories:
  - podcasts
tags:
  - language
  - english
toc: true
toc_sticky: true

date: 2025-04-05
last_modified_at: 2025-04-05
comments: true
thumbnail: assets/podcast/TedTech.jpg
---

## Source üéß
[**How a worm could save humanity from bad AI | Ramin Hasani**](https://podcasts.apple.com/kr/podcast/ted-tech/id470624027?i=1000685255753)  <br>
 \- TED Tech (TED Audio Collective)

<br><br>

## Sentences ‚úçÔ∏è

1. we have tools to really understand and **pinpoint** which part of the system is responsible for what.
   - `pinpoint`: To locate or identify something very precisely or accurately.
   - New sentence: The technician was able to pinpoint the source of the network failure within minutes.

 
2. because you understand it. You can never let it go **rogue**.
    - `rogue`: Acting unpredictably or dangerously, often outside of rules or control.
    - New sentence: If the software goes rogue, it could start making decisions without any human oversight.

 
3. So all of the crises we are dealing with right now, you know, **doomsday** kind of scenarios, is all about scaling a technology that we don't understand.
    - `doomsday`: A time or event of catastrophic destruction or disaster, often associated with the end of the world.
    - New sentence: Many scientists warn that ignoring climate change could bring about a doomsday scenario.
    
<br><br>

## Summarization üëÄ
Ramin Hasani envisions an AI that doesn't just solve equations but helps humans grow and understand the world. He is the co-inventor of Liquid Neural Networks, inspired by nature and capable of adapting through feedback, like the human brain. These networks are modeled partly on the nervous system of a simple worm, C. elegans, which shares 75% of its genome with humans. By mimicking the worm‚Äôs neural structure, Liquid AI systems gain flexibility and explainability, unlike traditional black-box AI models. This allows researchers to pinpoint exactly which part of the system is responsible for certain outputs.


Hasani argues that AI must remain understandable to stay under human control, especially as it becomes more powerful. Liquid Neural Networks are "white box" systems, meaning their inner workings are transparent and interpretable. This design makes it possible to safely scale AI without fear of it going rogue. Hasani believes that nature offers evolutionary shortcuts for building efficient AI systems. Ultimately, he wants AI to be a trustworthy partner in solving global challenges‚Äîfrom energy and economics to conflict and human potential.
<br><br>